Saving all output to "!!{outputDirectory}!!/index_creation.q.raw". Enter "record" with no arguments to stop it.
>>>  !run !!{qFileDirectory}!!/index_creation.q
>>>  drop index src_index_2 on src;
No rows affected 
>>>  drop index src_index_3 on src;
No rows affected 
>>>  drop index src_index_4 on src;
No rows affected 
>>>  drop index src_index_5 on src;
No rows affected 
>>>  drop index src_index_6 on src;
No rows affected 
>>>  drop index src_index_7 on src;
No rows affected 
>>>  drop index src_index_8 on src;
No rows affected 
>>>  drop index src_index_9 on src;
No rows affected 
>>>  drop table `_t`;
No rows affected 
>>>  
>>>  create index src_index_2 on table src(key) as 'compact' WITH DEFERRED REBUILD;
No rows affected 
>>>  desc extended default__src_src_index_2__;
'col_name','data_type','comment'
'Table default__src_src_index_2__ does not exist','',''
1 row selected 
>>>  
>>>  create index src_index_3 on table src(key) as 'compact' WITH DEFERRED REBUILD in table src_idx_src_index_3;
No rows affected 
>>>  desc extended src_idx_src_index_3;
'col_name','data_type','comment'
'key','string',''
'_bucketname','string',''
'_offsets','array<bigint>',''
'','',''
'Detailed Table Information','Table(tableName:src_idx_src_index_3, dbName:index_creation, owner:null, createTime:!!UNIXTIME!!, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:key, type:string, comment:null), FieldSchema(name:_bucketname, type:string, comment:), FieldSchema(name:_offsets, type:array<bigint>, comment:)], location:!!{hive.metastore.warehouse.dir}!!/index_creation.db/src_idx_src_index_3, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[Order(col:key, order:1)], parameters:{}), partitionKeys:[], parameters:{transient_lastDdlTime=!!UNIXTIME!!}, viewOriginalText:null, viewExpandedText:null, tableType:INDEX_TABLE)',''
5 rows selected 
>>>  
>>>  create index src_index_4 on table src(key) as 'compact' WITH DEFERRED REBUILD ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t' STORED AS TEXTFILE;
No rows affected 
>>>  desc extended default__src_src_index_4__;
'col_name','data_type','comment'
'Table default__src_src_index_4__ does not exist','',''
1 row selected 
>>>  
>>>  create index src_index_5 on table src(key) as 'compact' WITH DEFERRED REBUILD ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t' ESCAPED BY '\\';
No rows affected 
>>>  desc extended default__src_src_index_5__;
'col_name','data_type','comment'
'Table default__src_src_index_5__ does not exist','',''
1 row selected 
>>>  
>>>  create index src_index_6 on table src(key) as 'compact' WITH DEFERRED REBUILD STORED AS RCFILE;
No rows affected 
>>>  desc extended default__src_src_index_6__;
'col_name','data_type','comment'
'Table default__src_src_index_6__ does not exist','',''
1 row selected 
>>>  
>>>  create index src_index_7 on table src(key) as 'compact' WITH DEFERRED REBUILD in table src_idx_src_index_7 STORED AS RCFILE;
No rows affected 
>>>  desc extended src_idx_src_index_7;
'col_name','data_type','comment'
'key','string',''
'_bucketname','string',''
'_offsets','array<bigint>',''
'','',''
'Detailed Table Information','Table(tableName:src_idx_src_index_7, dbName:index_creation, owner:null, createTime:!!UNIXTIME!!, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:key, type:string, comment:null), FieldSchema(name:_bucketname, type:string, comment:), FieldSchema(name:_offsets, type:array<bigint>, comment:)], location:!!{hive.metastore.warehouse.dir}!!/index_creation.db/src_idx_src_index_7, inputFormat:org.apache.hadoop.hive.ql.io.RCFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.RCFileOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[Order(col:key, order:1)], parameters:{}), partitionKeys:[], parameters:{transient_lastDdlTime=!!UNIXTIME!!}, viewOriginalText:null, viewExpandedText:null, tableType:INDEX_TABLE)',''
5 rows selected 
>>>  
>>>  create index src_index_8 on table src(key) as 'compact' WITH DEFERRED REBUILD IDXPROPERTIES ("prop1"="val1", "prop2"="val2");
No rows affected 
>>>  desc extended default__src_src_index_8__;
'col_name','data_type','comment'
'Table default__src_src_index_8__ does not exist','',''
1 row selected 
>>>  
>>>  create index src_index_9 on table src(key) as 'compact' WITH DEFERRED REBUILD TBLPROPERTIES ("prop1"="val1", "prop2"="val2");
No rows affected 
>>>  desc extended default__src_src_index_9__;
'col_name','data_type','comment'
'Table default__src_src_index_9__ does not exist','',''
1 row selected 
>>>  
>>>  create table `_t`(`_i` int, `_j` int);
No rows affected 
>>>  create index x on table `_t`(`_j`) as 'compact' WITH DEFERRED REBUILD;
No rows affected 
>>>  alter index x on `_t` rebuild;
No rows affected 
>>>  
>>>  create index x2 on table `_t`(`_i`,`_j`) as 'compact' WITH DEFERRED 
REBUILD;
No rows affected 
>>>  alter index x2 on `_t` rebuild;
No rows affected 
>>>  
>>>  drop index src_index_2 on src;
No rows affected 
>>>  drop index src_index_3 on src;
No rows affected 
>>>  drop index src_index_4 on src;
No rows affected 
>>>  drop index src_index_5 on src;
No rows affected 
>>>  drop index src_index_6 on src;
No rows affected 
>>>  drop index src_index_7 on src;
No rows affected 
>>>  drop index src_index_8 on src;
No rows affected 
>>>  drop index src_index_9 on src;
No rows affected 
>>>  drop table `_t`;
No rows affected 
>>>  
>>>  show tables;
'tab_name'
'primitives'
'src'
'src1'
'src_json'
'src_sequencefile'
'src_thrift'
'srcbucket'
'srcbucket2'
'srcpart'
9 rows selected 
>>>  !record
