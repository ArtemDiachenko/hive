Saving all output to "!!{outputDirectory}!!/str_to_map.q.raw". Enter "record" with no arguments to stop it.
>>>  !run !!{qFileDirectory}!!/str_to_map.q
>>>  desc function str_to_map;
'tab_name'
'str_to_map(text, delimiter1, delimiter2) - Creates a map by parsing text '
1 row selected 
>>>  desc function extended str_to_map;
'tab_name'
'str_to_map(text, delimiter1, delimiter2) - Creates a map by parsing text '
'Split text into key-value pairs using two delimiters. The first delimiter seperates pairs, and the second delimiter sperates key and value. If only one parameter is given, default delimiters are used: ',' as delimiter1 and '=' as delimiter2.'
2 rows selected 
>>>  
>>>  explain select str_to_map('a=1,b=2,c=3',',','=')['a'] from src limit 3;
'Explain'
'ABSTRACT SYNTAX TREE:'
'  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR ([ (TOK_FUNCTION str_to_map 'a=1,b=2,c=3' ',' '=') 'a'))) (TOK_LIMIT 3)))'
''
'STAGE DEPENDENCIES:'
'  Stage-1 is a root stage'
'  Stage-0 is a root stage'
''
'STAGE PLANS:'
'  Stage: Stage-1'
'    Map Reduce'
'      Alias -> Map Operator Tree:'
'        src '
'          TableScan'
'            alias: src'
'            Select Operator'
'              expressions:'
'                    expr: str_to_map('a=1,b=2,c=3',',','=')['a']'
'                    type: string'
'              outputColumnNames: _col0'
'              Limit'
'                File Output Operator'
'                  compressed: false'
'                  GlobalTableId: 0'
'                  table:'
'                      input format: org.apache.hadoop.mapred.TextInputFormat'
'                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
''
'  Stage: Stage-0'
'    Fetch Operator'
'      limit: 3'
''
''
32 rows selected 
>>>  select str_to_map('a=1,b=2,c=3',',','=')['a'] from src limit 3;
'_c0'
'1'
'1'
'1'
3 rows selected 
>>>  
>>>  explain select str_to_map('a:1,b:2,c:3') from src limit 3;
'Explain'
'ABSTRACT SYNTAX TREE:'
'  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_FUNCTION str_to_map 'a:1,b:2,c:3'))) (TOK_LIMIT 3)))'
''
'STAGE DEPENDENCIES:'
'  Stage-1 is a root stage'
'  Stage-0 is a root stage'
''
'STAGE PLANS:'
'  Stage: Stage-1'
'    Map Reduce'
'      Alias -> Map Operator Tree:'
'        src '
'          TableScan'
'            alias: src'
'            Select Operator'
'              expressions:'
'                    expr: str_to_map('a:1,b:2,c:3')'
'                    type: map<string,string>'
'              outputColumnNames: _col0'
'              Limit'
'                File Output Operator'
'                  compressed: false'
'                  GlobalTableId: 0'
'                  table:'
'                      input format: org.apache.hadoop.mapred.TextInputFormat'
'                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
''
'  Stage: Stage-0'
'    Fetch Operator'
'      limit: 3'
''
''
32 rows selected 
>>>  select str_to_map('a:1,b:2,c:3') from src limit 3;
'_c0'
'{b=2, c=3, a=1}'
'{b=2, c=3, a=1}'
'{b=2, c=3, a=1}'
3 rows selected 
>>>  
>>>  explain select str_to_map('a:1,b:2,c:3',',',':') from src limit 3;
'Explain'
'ABSTRACT SYNTAX TREE:'
'  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_FUNCTION str_to_map 'a:1,b:2,c:3' ',' ':'))) (TOK_LIMIT 3)))'
''
'STAGE DEPENDENCIES:'
'  Stage-1 is a root stage'
'  Stage-0 is a root stage'
''
'STAGE PLANS:'
'  Stage: Stage-1'
'    Map Reduce'
'      Alias -> Map Operator Tree:'
'        src '
'          TableScan'
'            alias: src'
'            Select Operator'
'              expressions:'
'                    expr: str_to_map('a:1,b:2,c:3',',',':')'
'                    type: map<string,string>'
'              outputColumnNames: _col0'
'              Limit'
'                File Output Operator'
'                  compressed: false'
'                  GlobalTableId: 0'
'                  table:'
'                      input format: org.apache.hadoop.mapred.TextInputFormat'
'                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
''
'  Stage: Stage-0'
'    Fetch Operator'
'      limit: 3'
''
''
32 rows selected 
>>>  select str_to_map('a:1,b:2,c:3',',',':') from src limit 3;
'_c0'
'{b=2, c=3, a=1}'
'{b=2, c=3, a=1}'
'{b=2, c=3, a=1}'
3 rows selected 
>>>  
>>>  explain select str_to_map(t.ss,',',':')['a'] 
from (select transform('a:1,b:2,c:3') using 'cat' as (ss) from src) t 
limit 3;
'Explain'
'ABSTRACT SYNTAX TREE:'
'  (TOK_QUERY (TOK_FROM (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TRANSFORM (TOK_EXPLIST 'a:1,b:2,c:3') TOK_SERDE TOK_RECORDWRITER 'cat' TOK_SERDE TOK_RECORDREADER (TOK_ALIASLIST ss)))))) t)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR ([ (TOK_FUNCTION str_to_map (. (TOK_TABLE_OR_COL t) ss) ',' ':') 'a'))) (TOK_LIMIT 3)))'
''
'STAGE DEPENDENCIES:'
'  Stage-1 is a root stage'
'  Stage-0 is a root stage'
''
'STAGE PLANS:'
'  Stage: Stage-1'
'    Map Reduce'
'      Alias -> Map Operator Tree:'
'        t:src '
'          TableScan'
'            alias: src'
'            Select Operator'
'              expressions:'
'                    expr: 'a:1,b:2,c:3''
'                    type: string'
'              outputColumnNames: _col0'
'              Transform Operator'
'                command: cat'
'                output info:'
'                    input format: org.apache.hadoop.mapred.TextInputFormat'
'                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
'                Select Operator'
'                  expressions:'
'                        expr: str_to_map(_col0,',',':')['a']'
'                        type: string'
'                  outputColumnNames: _col0'
'                  Limit'
'                    File Output Operator'
'                      compressed: false'
'                      GlobalTableId: 0'
'                      table:'
'                          input format: org.apache.hadoop.mapred.TextInputFormat'
'                          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
''
'  Stage: Stage-0'
'    Fetch Operator'
'      limit: 3'
''
''
42 rows selected 
>>>  select str_to_map(t.ss,',',':')['a'] 
from (select transform('a:1,b:2,c:3') using 'cat' as (ss) from src) t 
limit 3;
'_c0'
'1'
'1'
'1'
3 rows selected 
>>>  
>>>  
>>>  drop table tbl_s2m;
No rows affected 
>>>  create table tbl_s2m as select 'ABC=CC_333=444' as t from src limit 3;
't'
No rows selected 
>>>  
>>>  select str_to_map(t,'_','=')['333'] from tbl_s2m;
'_c0'
'444'
'444'
'444'
3 rows selected 
>>>  
>>>  drop table tbl_s2m;
No rows affected 
>>>  !record
